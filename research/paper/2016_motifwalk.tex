% Author: Hoang NT
% Created: 2016-06-26

\documentclass{sig-alternate-05-2015}

\newdef{definition}{Definition}
\usepackage{amsmath, amsfonts, amssymb}

\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\doi{10.475/123_4}

% ISBN
\isbn{123-4567-24-567/08/06}

%Conference
\conferenceinfo{WSDM '17}{February 2--9, 2017, Cambridge, UK}

\acmPrice{\$15.00}

%
% --- Author Metadata here ---
\conferenceinfo{Web Search and Data Mining}{'17 Cambridge, USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Motif-Aware Graph Embedding
%\titlenote{Funded by Japanese Governement.}
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}
}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Hoang Nguyen\\ %\titlenote{Hoang Nguyen is a master student.}\\
       \affaddr{Tokyo Institute of Technology}\\
       \email{hoangnt@ai.cs.titech.ac.jp}
\alignauthor
Nukui Shun\\ 
       \affaddr{Tokyo Institute of Technology}\\
       \email{nukui.s@net.c.titech.ac.jp}
% 2nd. author
\alignauthor
Tsuyoshi Murata\\ %\titlenote{Prof. Murata is the supervisor}\\
       \affaddr{Tokyo Insitute of Techonology}\\
       \email{murata@c.titech.ac.jp}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{26 June 2016}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Given a large complex graph, how can we learn a lower dimension
vector representation of each vertex that preserves structural 
information? Recent advancements in graph embedding have used
word embedding techniques and deep architectures to propose a
feasible answer to this question. However, most of these work
considers the notion of ``neighborhood'' by node adjacency only.
In this paper, we propose a novel graph embedding algorithm that
employs motif structures into the latent vector representation 
learning process. By contrasting between sets of nodes created 
by random walks and sets of nodes created by biased \emph{motif walk},
we show that embedding results of our algorithm are more
accurate in various benchmark graph mining tasks compared to
existing algorithms. The source code and results of our algorthms
is available online at \url{https://github.com/anonsyuushi/mage.git}.
\end{abstract}



%
% Generated CCS code: dl.acm.org/ccs/ccs.cfm
%

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010257.10010293.10010319</concept_id>
<concept_desc>Computing methodologies~Learning latent representations</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257.10010293.10010294</concept_id>
<concept_desc>Computing methodologies~Neural networks</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10002950.10003624.10003633</concept_id>
<concept_desc>Mathematics of computing~Graph theory</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Learning latent representations}
\ccsdesc[300]{Computing methodologies~Neural networks}
\ccsdesc[300]{Mathematics of computing~Graph theory}


%
% End generated code
%

%
%  Use this command to print the description
%
\printccsdesc

% We no longer use \terms command
%\terms{Theory}

\keywords{Distributed representation; Graph embedding; motif; auto-encoder; word2vec; MAGE}

\section{Introduction}

Meaningful distributed representation of a high dimensional sparse
dataset has proven to be useful for various machine learning tasks.
For example, the \textbf{dense vector representation} of words in 
word2vec framework \cite{w2v} has enabled machine learning
researchers to \textbf{put applications and citation of word2vec here}.

Recently, starting from 2014 with the \emph{DeepWalk} algorithm \cite{deepwalk},
there has been many proposed algorithms to encode a network's component such as
vertices or edges into a high dimensional real vector. The motivation behind
these algorithms is to learn a dense representation of the network anologous 
to learning a dense representation of a word \cite{w2v}. By encoding the 
whole network into vectors, graph embedding algorithms have
enabled network researcher to use the power of neural network techniques on
network data \cite{all_deep_learning_on_network}. Basically this solve the
sparsity problem of the network.

Our algorithm outperfroms every other algorithms on their test.
We conducted experiment throughly and carefully. Each experiment is ran
with the same condition 10 times and take average, we have all the deviation
stuff that others don't have. Really, it's really a very good paper.
Please accept it so I can go to UK for a vacation. Please.

The good news is, with only a handful of manual
settings\footnote{Two of these, the {\texttt{\char'134 numberofauthors}}
and {\texttt{\char'134 alignauthor}} commands, you have
already used; another, {\texttt{\char'134 balancecolumns}}, will
be used in your very last run of \LaTeX\ to ensure
balanced column heights on the last page.}, the \LaTeX\ document
class file handles all of this for you.

The remainder of this document is concerned with showing, in
the context of an ``actual'' document, the \LaTeX\ commands
specifically available for denoting the structure of a
proceedings paper, rather than with giving rigorous descriptions
or explanations of such commands.

\section{Related work}

In the context of topological graph theory, an embedding refers to a
representation of a graph $G$ on a surface $\Sigma$. Graph embedding
can also be viewed as dimension reduction when the dimensionality
of the surface $\Sigma$ is less than the dimensionality of the graph.
Meaningful graph embedding, in practice, is low dimensionality vector
representations of vertices preserving some analytical properties of
the graph. Generally, there are two main approaches to obtain high-quality
graph embeddings: affinity matrix factorization and machine learning
with neural networks.

\subsection{Matrix factorization}

== NUKUI ==

\subsection{Skipgram model}

Our work in this paper is directly related to
the \emph{word2vec} model \cite{w2c}. More specifically,
the 

The literature of graph embedding start with
matrix decomposition techniques \cite{la}. Super
professor et. al. perform amazing works
and achieved many success. Traditionally, graph
clustering procedure where similarity between
nodes or edges is defined and group together
by some similarity metric. This leads to the
notation of closeness and hence community.
However, one limitation of these classical 
graph embedding technique is that it depends 
on matrix decompositon which is very computational 
expensive.

Recently, with the emerging of deep neural network
models such as autoencoder \cite{la}, restricted 
Bolzman machine \cite{la}, and some other that I will
fill here later. Inspired by these advancement of
natural language processing neural network models,
Peperozi et. al. \cite{deepwalk} proposed a graph
embedding framework named DeepWalk. By taking advantage
of the network structure and create an artificial
``node corpus'' by performing random walk, DeepWalk
has achieved good performance and inspired any
following researches. Since 2014, many graph embedding
model based on random walk has been proposed such as
LINE, GraRep, etc. These embedding algorithm proved
its efficiency and usefullness in various graph
mining tasks and classification problem in large graph.

Out of the aforementioned embedding algorithms,
LINE has taken our notice. LINE model improved
DeepWalk by incooporating the notation of second
order proximity to the learning task. This leads
to its outstanding performance without other auxilariy
information. There are some research that has 
good result in embedding too, but out of all research
that only use graph structure, LINE is the best.
We think that the key to LINE's success was
the second order proximity added to the original
embedding scheme. However, LINE perform extremely well
in network with citation-like structure. In other word,
LINE is very good for network with wedge motif.
From this observation, we think that if we can 
incooporate the most popular substructure of the
graph to the embedding scheme, we can learn better
vector representation.

\subsection{Motif in Graph}
Motif is defined as a small subgraph that has
some funny characteristic \cite{la}, maybe cite some
of Jure's work here.

\section{Motif-aware graph embedding}

As mentioned in the previous sessions, our work aims
to improve embedding quality by manipulating the graph
sampling process. We have two sampling processes in 
your framework. The first process uses conventional 
random walk and a ``skip window'' to generate positive
samples, while negative samples are picked from a noise
distribution $p_n(x)$. The second uses a pre-defined 
\emph{motif walk} to generate positive samples, while
negative samples is generated from a contrasting distribution:

\begin{equation}
  p_{\scalebox{0.7}{mc}}(x) = 
    \boldsymbol f\left(p^t_{\scalebox{0.7}{m}}(x) \ || \ p^t_{\scalebox{0.7}{r}}(x)\right),
\end{equation}

where $\boldsymbol f(.)$ is chosen to be a distance function that
yields high probability for node $x$ when $x$ is more
likely to appear in random walk starting from node $t$
than in motif walk starting from node $t$. $p^t_m(x)$ and
$p^t_r(x)$ are distribution of nodes count in motif walk
and random walk starting from vertex $t$. 

Our model is a variant of the skipgram model \cite{w2v}
using the softmax function, in which we define the coocurence 
conditional probability of a ``class'' vertex  given 
the ``target'' vertex as:

\begin{equation}
  p\left(v_{\scalebox{0.7}{class}} \ | \ v_{\scalebox{0.7}{target}}\right) 
    = \frac{\exp(\omega^\top_c \cdot \omega_t)}{\sum^{|V|}_{i=1} \exp(\omega^\top_i \cdot \omega_t)}
\end{equation}

Despite the efficiency and simplicity of this model,
the task of computing the normalization factor requires
summing all over the graph's vertices is intractable
for large graph. To solve this normalization problem,
estimation techiques such as hierachial softmax \cite{hsoftmax}, 
noise contrastive estimation \cite{nce}, and negative
sampling \cite{w2v} are employed in the recent graph
embedding models \cite{deepwalk, line, platenoid}.
We define the objective function with negative sampling
for our model as follow:

\begin{equation}
  \begin{aligned}
    \mathcal{L} & = \log p\left(v_{\scalebox{0.7}{class}} \ | \ v_{\scalebox{0.7}{target}}\right) \\
      & = \log \sigma \left(\omega^\top_c \cdot \omega_t\right) + 
        \sum^{k}_{i=1} \mathds{E}_{\omega_s \sim p_{\scalebox{0.7}{mc}}(\omega)} \left[\sigma (-\omega^\top_s \cdot \omega_t)\right]
  \end{aligned}
\end{equation}

\subsection{Graph sampling process}

\begin{definition}
A graph is represented as $G = (V,E)$, where $V$ is the
set of vertices and $E$ is the set of edges between vertices.
Each edges $e \in E$ is an ordered pair $e = (u,v)$ where
$u, v \in V$. A graph is called \emph{undirected} when
$(u,v) \equiv (v,u)$, and \emph{directed} when $(u,v) \not\equiv (v,u)$.
\end{definition}

Typically, the body of a paper is organized
into a hierarchical structure, with numbered or unnumbered
headings for sections, subsections, sub-subsections, and even
smaller sections.  The command \texttt{{\char'134}section} that
precedes this paragraph is part of such a
hierarchy.\footnote{This is the second footnote.  It
starts a series of three footnotes that add nothing
informational, but just give an idea of how footnotes work
and look. It is a wordy one, just so you see
how a longish one plays out.} \LaTeX\ handles the numbering
and placement of these headings for you, when you use
the appropriate heading commands around the titles
of the headings.  If you want a sub-subsection or
smaller part to be unnumbered in your output, simply append an
asterisk to the command name.  Examples of both
numbered and unnumbered headings will appear throughout the
balance of this sample document.

Because the entire article is contained in
the \textbf{document} environment, you can indicate the
start of a new paragraph with a blank line in your
input file; that is why this sentence forms a separate paragraph.

\subsection{Neural network optimization}

\subsection{Training procedure}

\section{Experiments}

\subsection{Type Changes and {\subsecit Special} Characters}
We have already seen several typeface changes in this sample.  You
can indicate italicized words or phrases in your text with
the command \texttt{{\char'134}textit}; emboldening with the
command \texttt{{\char'134}textbf}
and typewriter-style (for instance, for computer code) with
\texttt{{\char'134}texttt}.  But remember, you do not
have to indicate typestyle changes when such changes are
part of the \textit{structural} elements of your
article; for instance, the heading of this subsection will
be in a sans serif\footnote{A third footnote, here.
Let's make this a rather short one to
see how it looks.} typeface, but that is handled by the
document class file. Take care with the use
of\footnote{A fourth, and last, footnote.}
the curly braces in typeface changes; they mark
the beginning and end of
the text that is to be in the different typeface.

You can use whatever symbols, accented characters, or
non-English characters you need anywhere in your document;
you can find a complete list of what is
available in the \textit{\LaTeX\
User's Guide}\cite{Lamport:LaTeX}.

\subsection{Math Equations}
You may want to display math equations in three distinct styles:
inline, numbered or non-numbered display.  Each of
the three are discussed in the next sections.

\subsubsection{Inline (In-text) Equations}
A formula that appears in the running text is called an
inline or in-text formula.  It is produced by the
\textbf{math} environment, which can be
invoked with the usual \texttt{{\char'134}begin. . .{\char'134}end}
construction or with the short form \texttt{\$. . .\$}. You
can use any of the symbols and structures,
from $\alpha$ to $\omega$, available in
\LaTeX\cite{Lamport:LaTeX}; this section will simply show a
few examples of in-text equations in context. Notice how
this equation: \begin{math}\lim_{n\rightarrow \infty}x=0\end{math},
set here in in-line math style, looks slightly different when
set in display style.  (See next section).

\subsubsection{Display Equations}
A numbered display equation -- one set off by vertical space
from the text and centered horizontally -- is produced
by the \textbf{equation} environment. An unnumbered display
equation is produced by the \textbf{displaymath} environment.

Again, in either environment, you can use any of the symbols
and structures available in \LaTeX; this section will just
give a couple of examples of display equations in context.
First, consider the equation, shown as an inline equation above:
\begin{equation}\lim_{n\rightarrow \infty}x=0\end{equation}
Notice how it is formatted somewhat differently in
the \textbf{displaymath}
environment.  Now, we'll enter an unnumbered equation:
\begin{displaymath}\sum_{i=0}^{\infty} x + 1\end{displaymath}
and follow it with another numbered equation:
\begin{equation}\sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f\end{equation}
just to demonstrate \LaTeX's able handling of numbering.

\subsection{Citations}
Citations to articles \cite{bowman:reasoning,
clark:pct, braams:babel, herlihy:methodology},
conference proceedings \cite{clark:pct} or
books \cite{salas:calculus, Lamport:LaTeX} listed
in the Bibliography section of your
article will occur throughout the text of your article.
You should use BibTeX to automatically produce this bibliography;
you simply need to insert one of several citation commands with
a key of the item cited in the proper location in
the \texttt{.tex} file \cite{Lamport:LaTeX}.
The key is a short reference you invent to uniquely
identify each work; in this sample document, the key is
the first author's surname and a
word from the title.  This identifying key is included
with each item in the \texttt{.bib} file for your article.

The details of the construction of the \texttt{.bib} file
are beyond the scope of this sample document, but more
information can be found in the \textit{Author's Guide},
and exhaustive details in the \textit{\LaTeX\ User's
Guide}\cite{Lamport:LaTeX}.

This article shows only the plainest form
of the citation command, using \texttt{{\char'134}cite}.
This is what is stipulated in the SIGS style specifications.
No other citation format is endorsed or supported.

\subsection{Tables}
Because tables cannot be split across pages, the best
placement for them is typically the top of the page
nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and
the table caption.  The contents of the table itself must go
in the \textbf{tabular} environment, to
be aligned properly in rows and columns, with the desired
horizontal and vertical rules.  Again, detailed instructions
on \textbf{tabular} material
is found in the \textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table 1 is included in the input file; compare the
placement of the table here with the table in the printed
dvi output of this document.

\begin{table}
\centering
\caption{Frequency of Special Characters}
\begin{tabular}{|c|c|l|} \hline
Non-English or Math&Frequency&Comments\\ \hline
\O & 1 in 1,000& For Swedish names\\ \hline
$\pi$ & 1 in 5& Common in math\\ \hline
\$ & 4 in 5 & Used in business\\ \hline
$\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
\hline\end{tabular}
\end{table}

To set a wider table, which takes up the whole width of
the page's live area, use the environment
\textbf{table*} to enclose the table's contents and
the table caption.  As with a single-column table, this wide
table will ``float" to a location deemed more desirable.
Immediately following this sentence is the point at which
Table 2 is included in the input file; again, it is
instructive to compare the placement of the
table here with the table in the printed dvi
output of this document.


\begin{table*}
\centering
\caption{Some Typical Commands}
\begin{tabular}{|c|c|l|} \hline
Command&A Number&Comments\\ \hline
\texttt{{\char'134}alignauthor} & 100& Author alignment\\ \hline
\texttt{{\char'134}numberofauthors}& 200& Author enumeration\\ \hline
\texttt{{\char'134}table}& 300 & For tables\\ \hline
\texttt{{\char'134}table*}& 400& For wider tables\\ \hline\end{tabular}
\end{table*}
% end the environment with {table*}, NOTE not {table}!

\subsection{Figures}
Like tables, figures cannot be split across pages; the
best placement for them
is typically the top or the bottom of the page nearest
their initial cite.  To ensure this proper ``floating'' placement
of figures, use the environment
\textbf{figure} to enclose the figure and its caption.

This sample document contains examples of \textbf{.eps} files to be
displayable with \LaTeX.  If you work with pdf\LaTeX, use files in the
\textbf{.pdf} format.  Note that most modern \TeX\ system will convert
\textbf{.eps} to \textbf{.pdf} for you on the fly.  More details on
each of these is found in the \textit{Author's Guide}.

\begin{figure}
\centering
\includegraphics{fly}
\caption{A sample black and white graphic.}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=1in, width=1in]{fly}
\caption{A sample black and white graphic
that has been resized with the \texttt{includegraphics} command.}
\end{figure}


As was the case with tables, you may want a figure
that spans two columns.  To do this, and still to
ensure proper ``floating'' placement of tables, use the environment
\textbf{figure*} to enclose the figure and its caption.
and don't forget to end the environment with
{figure*}, not {figure}!

\begin{figure*}
\centering
\includegraphics{flies}
\caption{A sample black and white graphic
that needs to span two columns of text.}
\end{figure*}


\begin{figure}
\centering
\includegraphics[height=1in, width=1in]{rosette}
\caption{A sample black and white graphic that has
been resized with the \texttt{includegraphics} command.}
\vskip -6pt
\end{figure}

\subsection{Theorem-like Constructs}
Other common constructs that may occur in your article are
the forms for logical constructs like theorems, axioms,
corollaries and proofs.  There are
two forms, one produced by the
command \texttt{{\char'134}newtheorem} and the
other by the command \texttt{{\char'134}newdef}; perhaps
the clearest and easiest way to distinguish them is
to compare the two in the output of this sample document:

This uses the \textbf{theorem} environment, created by
the\linebreak\texttt{{\char'134}newtheorem} command:
\newtheorem{theorem}{Theorem}
\begin{theorem}
Let $f$ be continuous on $[a,b]$.  If $G$ is
an antiderivative for $f$ on $[a,b]$, then
\begin{displaymath}\int^b_af(t)dt = G(b) - G(a).\end{displaymath}
\end{theorem}

The other uses the \textbf{definition} environment, created
by the \texttt{{\char'134}newdef} command:
\begin{definition}
If $z$ is irrational, then by $e^z$ we mean the
unique number which has
logarithm $z$: \begin{displaymath}{\log e^z = z}\end{displaymath}
\end{definition}

Two lists of constructs that use one of these
forms is given in the
\textit{Author's  Guidelines}.
 
There is one other similar construct environment, which is
already set up
for you; i.e. you must \textit{not} use
a \texttt{{\char'134}newdef} command to
create it: the \textbf{proof} environment.  Here
is a example of its use:
\begin{proof}
Suppose on the contrary there exists a real number $L$ such that
\begin{displaymath}
\lim_{x\rightarrow\infty} \frac{f(x)}{g(x)} = L.
\end{displaymath}
Then
\begin{displaymath}
l=\lim_{x\rightarrow c} f(x)
= \lim_{x\rightarrow c}
\left[ g{x} \cdot \frac{f(x)}{g(x)} \right ]
= \lim_{x\rightarrow c} g(x) \cdot \lim_{x\rightarrow c}
\frac{f(x)}{g(x)} = 0\cdot L = 0,
\end{displaymath}
which contradicts our assumption that $l\neq 0$.
\end{proof}

Complete rules about using these environments and using the
two different creation commands are in the
\textit{Author's Guide}; please consult it for more
detailed instructions.  If you need to use another construct,
not listed therein, which you want to have the same
formatting as the Theorem
or the Definition\cite{salas:calculus} shown above,
use the \texttt{{\char'134}newtheorem} or the
\texttt{{\char'134}newdef} command,
respectively, to create it.

\subsection*{A {\secit Caveat} for the \TeX\ Expert}
Because you have just been given permission to
use the \texttt{{\char'134}newdef} command to create a
new form, you might think you can
use \TeX's \texttt{{\char'134}def} to create a
new command: \textit{Please refrain from doing this!}
Remember that your \LaTeX\ source code is primarily intended
to create camera-ready copy, but may be converted
to other forms -- e.g. HTML. If you inadvertently omit
some or all of the \texttt{{\char'134}def}s recompilation will
be, to say the least, problematic.

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{2016_motifwalk}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Headings in Appendices}
The rules about hierarchical headings discussed above for
the body of the article are different in the appendices.
In the \textbf{appendix} environment, the command
\textbf{section} is used to
indicate the start of each Appendix, with alphabetic order
designation (i.e. the first is A, the second B, etc.) and
a title (if you include one).  So, if you need
hierarchical structure
\textit{within} an Appendix, start with \textbf{subsection} as the
highest level. Here is an outline of the body of this
document in Appendix-appropriate form:
\subsection{Introduction}
\subsection{The Body of the Paper}
\subsubsection{Type Changes and  Special Characters}
\subsubsection{Math Equations}
\paragraph{Inline (In-text) Equations}
\paragraph{Display Equations}
\subsubsection{Citations}
\subsubsection{Tables}
\subsubsection{Figures}
\subsubsection{Theorem-like Constructs}
\subsubsection*{A Caveat for the \TeX\ Expert}
\subsection{Conclusions}
\subsection{Acknowledgments}
\subsection{Additional Authors}
This section is inserted by \LaTeX; you do not insert it.
You just add the names and information in the
\texttt{{\char'134}additionalauthors} command at the start
of the document.
\subsection{References}
\section{More Help for the Hardy}
The sig-alternate.cls file itself is chock-full of succinct
and helpful comments.  If you consider yourself a moderately
experienced to expert user of \LaTeX, you may find reading
it useful but please remember not to change it.
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
